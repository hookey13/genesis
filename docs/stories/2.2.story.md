# Story 2.2: Statistical Arbitrage Engine

## Status
Done

## Story
**As an** arbitrage trader,
**I want** to detect price divergences between correlated pairs,
**so that** I can profit from mean reversion

## Acceptance Criteria
1. Correlation calculation between stablecoin pairs (USDT/USDC/BUSD)
2. Z-score calculation for divergence detection
3. 2-sigma threshold alerting for entry signals
4. Historical spread analysis (20-day rolling window)
5. Cointegration testing for pair validation
6. Signal generation with confidence scores
7. Backtesting framework for strategy validation
8. Performance attribution by pair and time

## Tasks / Subtasks
- [x] Create statistical arbitrage analytics module (AC: 1, 2, 5)
  - [x] Create `genesis/analytics/statistical_arb.py` with core arbitrage logic
  - [x] Implement `calculate_correlation(pair1: str, pair2: str, window: int) -> Decimal` for pair correlation
  - [x] Add `calculate_zscore(price1: Decimal, price2: Decimal, window: int) -> Decimal` for divergence detection
  - [x] Implement `test_cointegration(pair1_prices: List[Decimal], pair2_prices: List[Decimal]) -> bool` using Augmented Dickey-Fuller test
  - [x] Create correlation matrix computation for multiple stablecoin pairs
  - [x] Use pandas DataFrame for efficient windowed calculations
- [x] Build spread analysis system (AC: 4, 6)
  - [x] Create `SpreadAnalyzer` class in `genesis/analytics/statistical_arb.py`
  - [x] Implement 20-day rolling window spread calculation using pandas rolling
  - [x] Add spread mean and standard deviation tracking
  - [x] Create `generate_signal(zscore: Decimal, threshold: Decimal) -> Signal` with confidence scoring
  - [x] Implement signal confidence based on spread stability and cointegration strength
  - [x] Add signal persistence tracking to avoid false positives
- [x] Implement threshold alerting system (AC: 3)
  - [x] Create `ThresholdMonitor` class with configurable sigma levels
  - [x] Implement 2-sigma threshold detection for entry signals
  - [x] Add event publishing for threshold breaches using event bus
  - [x] Create `ArbitrageSignalEvent` in `genesis/core/events.py`
  - [x] Implement cooldown period to prevent alert spam (minimum 5 minutes between alerts)
- [x] Create database models for arbitrage data (AC: 1, 4, 8)
  - [x] Add `ArbitrageSignal` model to `genesis/data/models_db.py`
  - [x] Create `arbitrage_signals` table in `genesis/data/sqlite_repo.py`
  - [x] Add `spread_history` table for historical spread tracking
  - [x] Implement repository methods for signal persistence
  - [x] Create indexes on symbol pairs and timestamps for query performance
- [x] Build backtesting framework (AC: 7, 8)
  - [x] Create `genesis/analytics/backtest_engine.py` for strategy validation
  - [x] Implement `BacktestEngine` class with historical data replay
  - [x] Add `run_backtest(strategy: StatisticalArb, start_date: datetime, end_date: datetime) -> BacktestResult`
  - [x] Create performance metrics calculation (Sharpe ratio, max drawdown, win rate)
  - [x] Implement performance attribution by pair and time period
  - [x] Add transaction cost modeling for realistic results
- [x] Integrate with market data service (AC: 1, 2, 4)
  - [x] Update `genesis/data/market_data_service.py` to support multi-pair price feeds
  - [x] Add method `get_price_history(symbol: str, window_days: int) -> List[Decimal]`
  - [x] Implement efficient data caching for historical calculations
  - [x] Create subscription manager for correlated pair monitoring
  - [x] Add real-time correlation updates using WebSocket feeds
- [x] Create unit tests for statistical components (AC: All)
  - [x] Create `tests/unit/test_statistical_arb.py` with correlation tests
  - [x] Add tests for z-score calculation with edge cases
  - [x] Test cointegration with known cointegrated and non-cointegrated series
  - [x] Mock market data for deterministic testing
  - [x] Test signal generation with various threshold scenarios
  - [x] Achieve 100% coverage for risk-critical calculations
- [x] Create integration tests for arbitrage system (AC: 7, 8)
  - [x] Create `tests/integration/test_arbitrage_engine.py`
  - [x] Test end-to-end signal generation from live data
  - [x] Validate backtest results against known historical opportunities
  - [x] Test database persistence and retrieval of signals
  - [x] Verify event publishing for threshold alerts

## Dev Notes

### Previous Story Insights
From Story 2.1 implementation:
- WebSocket manager successfully handles gap detection and reconnection with 60s max backoff
- Market data service provides real-time price feeds and order book management
- Event bus implemented with priority lanes for event publishing
- Circular buffers (deque with maxlen=1000) used for memory efficiency
- SQLite database configured with WAL mode for better concurrency
- All financial calculations use Decimal type (never float)

### Project Structure Notes
**IMPORTANT TIER RESTRICTION**: The standard location for strategies (`genesis/strategies/strategist/statistical_arb.py`) is LOCKED until $10k+ tier is reached [Source: architecture/source-tree.md#line 79]. 

For the current $500-$1k tier (Epic 2), the statistical arbitrage engine must be implemented as an analytics component in `genesis/analytics/statistical_arb.py` [Source: architecture/source-tree.md#line 98-103].

### Data Models
**PositionCorrelation Model** [Source: architecture/data-models.md#PositionCorrelation]:
```python
- correlation_id: UUID
- position1_id: UUID
- position2_id: UUID  
- correlation_coefficient: Decimal  # Range: -1 to 1
- calculation_window: Integer       # Minutes used for calculation
- calculated_at: DateTime
- alert_triggered: Boolean          # Whether >60% threshold hit
```

**MarketState Model** (existing from Story 2.1) [Source: architecture/data-models.md#MarketState]:
```python
- volatility_atr: Decimal
- spread_basis_points: Integer
- volume_24h: Decimal
- liquidity_score: Decimal
```

### Database Schema
**position_correlations Table** [Source: architecture/database-schema.md#Phase 1]:
```sql
CREATE TABLE position_correlations (
    correlation_id TEXT PRIMARY KEY,
    position1_id TEXT NOT NULL,
    position2_id TEXT NOT NULL,
    correlation_coefficient TEXT NOT NULL,  -- Decimal as string
    calculation_window INTEGER NOT NULL,     -- minutes
    calculated_at TIMESTAMP NOT NULL,
    alert_triggered BOOLEAN NOT NULL DEFAULT FALSE,
    FOREIGN KEY (position1_id) REFERENCES positions(position_id),
    FOREIGN KEY (position2_id) REFERENCES positions(position_id),
    CHECK (correlation_coefficient BETWEEN -1 AND 1)
);
CREATE INDEX idx_correlations_positions ON position_correlations(position1_id, position2_id);
```

**New Tables Required** (not in existing schema):
```sql
-- arbitrage_signals table
CREATE TABLE arbitrage_signals (
    signal_id TEXT PRIMARY KEY,
    pair1_symbol TEXT NOT NULL,
    pair2_symbol TEXT NOT NULL,
    zscore TEXT NOT NULL,           -- Decimal as string
    threshold_sigma REAL NOT NULL,
    signal_type TEXT NOT NULL,      -- 'ENTRY' or 'EXIT'
    confidence_score TEXT NOT NULL,  -- Decimal 0-1
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- spread_history table  
CREATE TABLE spread_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    pair1_symbol TEXT NOT NULL,
    pair2_symbol TEXT NOT NULL,
    spread_value TEXT NOT NULL,     -- Decimal as string
    recorded_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
);
```

### Technical Stack and Libraries
[Source: architecture/tech-stack.md#Technology Stack Table]:
- **pandas 2.2.0**: Required for statistical calculations, rolling windows, correlation matrices
- **numpy 1.26.3**: Array operations, cointegration testing, fast numerical computation
- **decimal (stdlib)**: All financial calculations to prevent float rounding errors
- **asyncio**: Async event-driven architecture for real-time processing
- **structlog 24.1.0**: Structured logging (no print statements allowed)

### Binance API Integration
[Source: architecture/external-apis.md#Key Endpoints]:
- `GET /api/v3/klines`: Historical candlestick data for correlation calculations
- `GET /api/v3/ticker/24hr`: 24hr price statistics for pair selection
- WebSocket streams for real-time correlation updates:
  - `/ws/<symbol>@trade`: Real-time trade executions
  - `/stream?streams=`: Combined streams for multiple pairs

### Critical Coding Standards
[Source: architecture/coding-standards.md#Critical Rules]:
- **NEVER use float for money** - Always use Decimal from decimal module
- **ALWAYS use database transactions** for multi-step operations
- **ALWAYS validate state after restart** - Never assume in-memory state
- **Money variables** must be suffixed with currency (e.g., `spread_usdt`)
- **ALWAYS use idempotency keys** for any order generation
- **Type hints are mandatory** for all functions
- **Use structlog for all logging** - no print statements
- **NEVER catch bare exceptions** - catch specific exceptions only

### Event Bus Integration
[Source: architecture/high-level-architecture.md#Architectural Patterns]:
- Event-Driven Architecture using asyncio event loops
- Publish events using: `event_bus.publish(event, Priority.NORMAL)`
- Create new event type `ArbitrageSignalEvent` in `genesis/core/events.py`

### File Locations
Based on project structure [Source: architecture/source-tree.md]:
```
genesis/analytics/
├── statistical_arb.py      # Main arbitrage engine (new file)
├── backtest_engine.py      # Backtesting framework (new file)
└── correlation.py          # Update existing with enhanced correlation logic

genesis/data/
├── models_db.py           # Add ArbitrageSignal model (update)
├── sqlite_repo.py         # Add arbitrage tables (update)
└── market_data_service.py # Add price history methods (update)

genesis/core/
└── events.py             # Add ArbitrageSignalEvent (update)

tests/unit/
└── test_statistical_arb.py  # Unit tests (new file)

tests/integration/
└── test_arbitrage_engine.py # Integration tests (new file)
```

## Testing
- Unit test files: `tests/unit/test_statistical_arb.py`
- Integration test files: `tests/integration/test_arbitrage_engine.py`
- Use pytest 8.0.0 with pytest-asyncio for async tests
- Mock market data using fixtures in `tests/fixtures/`
- Test with deterministic data for reproducible results
- Coverage target: 100% for risk-critical calculations (correlation, z-score, signals)
- Use VCR.py for recording API responses when available
- Performance benchmarks: calculations must complete in <100ms

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-25 | 1.0 | Initial story creation | Scrum Master Bob |
| 2025-08-25 | 1.1 | Validated and approved - Implementation Readiness Score 10/10 | Product Owner Sarah |

## Dev Agent Record

### Agent Model Used
claude-opus-4-1-20250805

### Debug Log References
- Fixed deprecated datetime.utcnow() usage with datetime.now(UTC)
- Resolved linting issues with ruff and black formatters
- Implemented simplified cointegration test due to statsmodels dependency constraints

### Completion Notes List
- Successfully implemented all acceptance criteria
- Created comprehensive statistical arbitrage engine with correlation, z-score, and cointegration testing
- Built complete backtesting framework with performance metrics
- Integrated with market data service for real-time and historical data
- Implemented database persistence for signals and spread history
- Created extensive unit and integration tests
- All code formatted with Black and linted with Ruff

### File List
- genesis/analytics/statistical_arb.py (NEW)
- genesis/analytics/backtest_engine.py (NEW)
- genesis/core/events.py (MODIFIED)
- genesis/data/models_db.py (MODIFIED)
- genesis/data/sqlite_repo.py (MODIFIED)
- genesis/data/market_data_service.py (MODIFIED)
- tests/unit/test_statistical_arb.py (NEW)
- tests/integration/test_arbitrage_engine.py (NEW)

## QA Results

### Review Date: 2025-08-25

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

The implementation demonstrates excellent quality with comprehensive statistical arbitrage functionality. The code properly implements correlation calculation, z-score detection, cointegration testing, spread analysis, and backtesting capabilities. All financial calculations correctly use the Decimal type, preventing float precision errors. The event-driven architecture is well integrated with proper event publishing for arbitrage signals.

### Refactoring Performed

No refactoring was necessary. The code is well-structured, follows SOLID principles, and maintains clear separation of concerns across the analytics, data, and core modules.

### Compliance Check

- Coding Standards: ✓ All code follows Python naming conventions, uses Decimal for financial calculations, uses structlog for logging
- Project Structure: ✓ Files correctly placed in genesis/analytics/ as required for $500-$1k tier
- Testing Strategy: ✓ Comprehensive unit and integration tests with good coverage
- All ACs Met: ✓ All 8 acceptance criteria fully implemented and tested

### Improvements Checklist

All items were reviewed and found to be already addressed:

- [x] Correlation calculation between stablecoin pairs implemented with caching
- [x] Z-score calculation with proper handling of edge cases
- [x] 2-sigma threshold alerting with cooldown periods
- [x] 20-day rolling window spread analysis using pandas
- [x] Cointegration testing with simplified ADF test
- [x] Signal generation with multi-factor confidence scoring
- [x] Complete backtesting framework with performance metrics
- [x] Performance attribution by pair and time period

### Security Review

No security vulnerabilities identified:
- No hardcoded credentials or API keys
- Proper input validation in all functions
- No SQL injection risks (parameterized queries used)
- Decimal type prevents financial calculation exploits

### Performance Considerations

Performance optimizations already implemented:
- Correlation caching with 5-minute TTL reduces redundant calculations
- Circular buffers (deque with maxlen) prevent memory leaks
- Efficient pandas operations for windowed calculations
- Async architecture ensures non-blocking operations

### Files Modified During Review

No files were modified during review - the implementation is production-ready.

### Gate Status

Gate: PASS → docs/qa/gates/2.2-statistical-arbitrage-engine.yml
Risk profile: Low risk - analytics component with no direct trading execution
NFR assessment: All non-functional requirements satisfied

### Recommended Status

✓ Ready for Done
(Story owner decides final status)